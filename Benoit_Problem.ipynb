{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benoit's Problem with various RTO Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import approx_fprime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Benoit Model (Modified Version) for Real Time Optimization without constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant Model \n",
    "def Benoit_Model(u,theta):\n",
    "    f = theta[0] * u[0] ** 2 + theta[1] * u[1] ** 2\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_model(u,theta):\n",
    "    g1 = 1. - theta[2]*u[0] + theta[3]*u[1] ** 2\n",
    "    return -g1\n",
    "\n",
    "# Actual Plant System\n",
    "def Benoit_System_1(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + u[0] * u[1] + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "def Benoit_System_2(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + (1 - u[0] * u[1])**2 + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_system(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] - 2. + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def con1_system_tight(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def Benoit_System_noiseless_1(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + u[0] * u[1]  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "def Benoit_System_noiseless_2(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + (1 - u[0] * u[1])**2  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_system_noiseless(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] - 2.  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def con1_system_tight_noiseless(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1]  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Optimization on cost function\n",
    "\n",
    "Optimization algorithm on cost function to find optimized input u given parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization on cost function\n",
    "def cost_optimize(theta,u0):\n",
    "    con = ({'type': 'ineq', \n",
    "            'fun': lambda u: con1_model(u,theta)}) \n",
    "    result = minimize(Benoit_Model,\n",
    "                    u0,\n",
    "                    constraints= con,\n",
    "                    method='SLSQP',\n",
    "                    options={'ftol': 1e-9},\n",
    "                    args= (theta))\n",
    "\n",
    "    return result.x,result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 2.00000000e+00 -1.89234472e-08], optimal output: 1.9999999999530884\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "u0 = [1,1] # Initial guess for optimization algorithm\n",
    "theta = [0.5,0.5,0.5,0.5]\n",
    "u,fun = cost_optimize(theta,u0)\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Model Adaptation\n",
    "\n",
    "We try to minimize difference between output of an actual plant and output of a model. \n",
    "\n",
    "The difference is measured by SSE (Sum of Squared Error), which is used for cost function to be minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function of adaptation\n",
    "def SSE(theta,u,plant_func,plant_constraint):\n",
    "\n",
    "    func_diff = plant_func(u) - Benoit_Model(u,theta)\n",
    "    con_diff = plant_constraint(u) - con1_model(u,theta)\n",
    "\n",
    "    return func_diff**2+con_diff**2\n",
    "\n",
    "# Model Adaptation (Optimization of Parameters)\n",
    "def SSE_optimize(plant_func,plant_constraint,theta0,u):\n",
    "\n",
    "    result = minimize(SSE,\n",
    "                      theta0,\n",
    "                      method='SLSQP',\n",
    "                      args= (u,plant_func,plant_constraint),\n",
    "                      options= {'ftol': 1e-9})\n",
    "    \n",
    "    return result.x,result.fun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function:13.0\n",
      "------------\n",
      "optimal hyperparameters:[0.99999998 0.5        2.00000001 0.5       ],\n",
      "optimal function: 1.1170386694296845e-15\n"
     ]
    }
   ],
   "source": [
    "# test for adaptation cost function\n",
    "x = SSE(theta = [0.5,0.5,0.5,0.5],\n",
    "        u = [2,0],\n",
    "        plant_func = Benoit_System_noiseless_1,\n",
    "        plant_constraint =con1_system_noiseless)\n",
    "\n",
    "print(f\"cost function:{x}\")\n",
    "print(\"------------\")\n",
    "\n",
    "# test for model adaptation method\n",
    "theta,fun = SSE_optimize(plant_func=Benoit_System_noiseless_1,\n",
    "                     plant_constraint=con1_system_noiseless,\n",
    "                     theta0=[0.5,0.5,0.5,0.5],\n",
    "                     u=[2.00000000e+00,-1.89234472e-08])\n",
    "\n",
    "print(f\"optimal hyperparameters:{theta},\\noptimal function: {fun}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Overall Algorithm\n",
    "\n",
    "### I. Model Adaptation on \"Benoit_System_noiseless_1\" plant system with \"con1_system_noiseless\" constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 2.00000000e+00 -1.89234472e-08], optimal output: 1.9999999999530884\n",
      "optimal hyperparameters:[0.99999998 0.5        2.00000001 0.5       ], cost: 1.1201679861431565e-15\n",
      "optimal input: [ 4.99999997e-01 -2.01114322e-09], optimal output: 0.2499999930048407\n",
      "optimal hyperparameters:[0.99999998 0.5        5.00000001 0.5       ], cost: 1.021228093130283e-16\n",
      "optimal input: [ 2.00000000e-01 -7.58719882e-09], optimal output: 0.039999999147657936\n",
      "optimal hyperparameters:[ 0.99999998  0.5        10.99999956  0.5       ], cost: 1.1769003276782473e-14\n",
      "optimal input: [ 9.09090946e-02 -7.58719882e-09], optimal output: 0.008264463333250038\n",
      "optimal hyperparameters:[ 0.99999998  0.5        23.00000238  0.5       ], cost: 7.926616316173199e-14\n",
      "optimal input: [ 4.34782564e-02 -7.35436818e-09], optimal output: 0.0018903587452594004\n",
      "optimal hyperparameters:[ 0.99999998  0.5        47.00000596  0.5       ], cost: 1.4051593931378817e-15\n"
     ]
    }
   ],
   "source": [
    "# Initial Guess (k=0)\n",
    "uk = [1,1]\n",
    "thetak = [0.5,0.5,0.5,0.5]\n",
    "\n",
    "# dictionary: uk_1, fun, thetak_1, cost, \n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "\n",
    "    # Model Optimization\n",
    "    uk_1,fun = cost_optimize(theta=thetak,u0=uk)\n",
    "    print(f\"optimal input: {uk_1}, optimal output: {fun}\")\n",
    "    \n",
    "    # Model Adaptation\n",
    "    thetak_1,cost = SSE_optimize(plant_func=Benoit_System_noiseless_1,\n",
    "                        plant_constraint=con1_system_noiseless,\n",
    "                        theta0=thetak,\n",
    "                        u=uk_1)\n",
    "    print(f\"optimal hyperparameters:{thetak_1}, cost: {cost}\")\n",
    "\n",
    "    uk = uk_1\n",
    "    thetak = thetak_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Optimized Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [0. 0.], optimal output: 0.0\n"
     ]
    }
   ],
   "source": [
    "u0 = [1,1] \n",
    "con = ({'type': 'ineq', \n",
    "        'fun': lambda u: con1_system_noiseless(u)}) \n",
    "result = minimize(Benoit_System_noiseless_1,\n",
    "                u0,\n",
    "                constraints= con,\n",
    "                method='SLSQP',\n",
    "                options={'ftol': 1e-9})\n",
    "\n",
    "u = result.x\n",
    "fun = result.fun\n",
    "\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "Notice that actual optimal input is [0,0] while the optimal input from model adaption converges to the model. However, the convergence is done with wrong hyperparameters especially on constraint con1_system_noiseless; notice constant increase in theta[2] (=47 at the last iteration). \n",
    "\n",
    "Moreover, the hyperparameters theta[1], theta[3] (=0.5,0.5) does not change because intermidiate optimal inputs have u[1] = 0 always. If the initial values were [0.1,0.1,0.1,0.1] then theta[1], theta[3] = 0.1 always. This makes hyperparameter to not get changed in model adaptation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Model Adaptation on \"Benoit_System_noiseless_1\" plant system with \"con1_system_tight_noiseless\" constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 2.00000000e+00 -1.89234472e-08], optimal output: 1.9999999999530884\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 2.6598920050906437e-16\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n"
     ]
    }
   ],
   "source": [
    "# Initial Guess (k=0)\n",
    "uk = [1,1]\n",
    "thetak = [0.5,0.5,0.5,0.5]\n",
    "\n",
    "# dictionary: uk_1, fun, thetak_1, cost, \n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Model Optimization\n",
    "    uk_1,fun = cost_optimize(theta=thetak,u0=uk)\n",
    "    print(f\"optimal input: {uk_1}, optimal output: {fun}\")\n",
    "    \n",
    "    # Model Adaptation\n",
    "    thetak_1,cost = SSE_optimize(plant_func=Benoit_System_noiseless_1,\n",
    "                        plant_constraint=con1_system_tight_noiseless,\n",
    "                        theta0=thetak,\n",
    "                        u=uk_1)\n",
    "    print(f\"optimal hyperparameters:{thetak_1}, cost: {cost}\")\n",
    "\n",
    "    uk = uk_1\n",
    "    thetak = thetak_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Optimized Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 0.3684571  -0.39299332], optimal output: 0.14540320807022292\n"
     ]
    }
   ],
   "source": [
    "u0 = [1,1] \n",
    "con = ({'type': 'ineq', \n",
    "        'fun': lambda u: con1_system_tight_noiseless(u)}) \n",
    "result = minimize(Benoit_System_noiseless_1,\n",
    "                u0,\n",
    "                constraints= con,\n",
    "                method='SLSQP',\n",
    "                options={'ftol': 1e-9})\n",
    "\n",
    "u = result.x\n",
    "fun = result.fun\n",
    "\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "TO BE WRITTEN:\n",
    "\n",
    "The result seems to show the lack of model flexibility, which prevents the optimal input from model to conver to actual optimal input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modifier Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Benoit Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant Model \n",
    "def Benoit_Model(u,theta,modifier):\n",
    "\n",
    "    f = theta[0] * u[0] ** 2 + theta[1] * u[1] ** 2 + np.sum(modifier[2] * u)\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_model(u,theta,modifier):\n",
    "\n",
    "    g1 = 1. - theta[2]*u[0] + theta[3]*u[1] ** 2 + modifier[0][0] + modifier[0][1] + np.sum(modifier[1]*u)\n",
    "    return -g1\n",
    "\n",
    "# Actual Plant System\n",
    "def Benoit_System_1(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + u[0] * u[1] + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "def Benoit_System_2(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + (1 - u[0] * u[1])**2 + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_system(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] - 2. + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def con1_system_tight(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def Benoit_System_noiseless_1(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + u[0] * u[1]  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "def Benoit_System_noiseless_2(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + (1 - u[0] * u[1])**2  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_system_noiseless(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] - 2.  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def con1_system_tight_noiseless(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1]  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Optimization on Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE MODIFIED\n",
    "def cost_optimize(u0,theta,modifier):\n",
    "\n",
    "    con = ({'type': 'ineq',\n",
    "            'fun': lambda u: con1_model(u,theta,modifier)})\n",
    "    \n",
    "    result = minimize((Benoit_Model),\n",
    "                    u0,\n",
    "                    constraints= con,\n",
    "                    method='SLSQP',\n",
    "                    options= {'ftol': 1e-9, 'disp': True},\n",
    "                    args= (theta,modifier))\n",
    "    \n",
    "    return result.x,result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 7.0000000000000355\n",
      "            Iterations: 3\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 3\n",
      "optimal input: [-5.         -1.00000001], optimal output: 7.0000000000000355\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "u0 = np.array([1,1]) # Initial guess for optimization algorithm\n",
    "modifier = np.array([[1,1],[1,1],[1,1]],dtype=object) # dtype=object: https://stackoverflow.com/questions/29877508/what-does-dtype-object-mean-while-creating-a-numpy-array\n",
    "theta = np.array([0.5,0.5,0.5,0.5])\n",
    "\n",
    "u,fun = cost_optimize(u0,theta,modifier)\n",
    "\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Modifier Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient modifier\n",
    "def gradient_estimation(u,du,fun):\n",
    "    \n",
    "    # Predicted gradient from real plant\n",
    "    gradient_u0 = (fun(u+[du,0]) - fun(u))/du\n",
    "    gradient_u1 = (fun(u+[0,du]) - fun(u))/du\n",
    "    gradient = [gradient_u0,gradient_u1]\n",
    "\n",
    "    return gradient\n",
    "\n",
    "# Modifier Update\n",
    "def modifier_update(u,theta,modifier,du,plant_fun,plant_con1):\n",
    "    \n",
    "    # Calculate relavent bias and gradients:\n",
    "    gradient_cost_p = gradient_estimation(u,du,plant_fun)\n",
    "    ## Gradient of plant constraint function\n",
    "    gradient_con1_p = gradient_estimation(u,du,plant_con1)\n",
    "    ## Gradient of model cost function\n",
    "    gradient_cost_m = approx_fprime(u,Benoit_Model,epsilon=1e-6,args=(theta,modifier))\n",
    "    ## Gradient of model constraint function\n",
    "    gradient_con1_m = approx_fprime(u,con1_model,epsilon=1e-6,args=(theta,modifier))\n",
    "    ## Gradient of plant cost function\n",
    "\n",
    "\n",
    "    epsil = plant_fun(u) - Benoit_Model(u,theta,modifier)\n",
    "    lamda_0 = gradient_cost_p - gradient_cost_m \n",
    "    lamda_1 = gradient_con1_p - gradient_con1_m\n",
    "\n",
    "    return [epsil,lamda_0,lamda_1]\n",
    "\n",
    "# Modifier Adaptation\n",
    "def modifier_adaptation(u,theta,modifier,du,plant_fun,plant_con1,K):\n",
    "    new_modifier = modifier_update(u,theta,modifier,du,plant_fun,plant_con1)\n",
    "    K_dimension = np.identity(np.shape(K)[0])\n",
    "    modifier = (np.identity(K_dimension) - K)*modifier + K*new_modifier\n",
    "\n",
    "    return modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
