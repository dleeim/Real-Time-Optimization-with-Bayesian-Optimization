{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benoit's Problem with various RTO Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import approx_fprime\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benoit's Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Actual Plant System\n",
    "def Benoit_System_1(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + u[0] * u[1] + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "def Benoit_System_2(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + (1 - u[0] * u[1])**2 + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_system(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] - 2. + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def con1_system_tight(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def Benoit_System_noiseless_1(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + u[0] * u[1]  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "def Benoit_System_noiseless_2(u):\n",
    "    f = u[0] ** 2 + u[1] ** 2 + (1 - u[0] * u[1])**2  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_system_noiseless(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1] - 2.  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1\n",
    "\n",
    "\n",
    "def con1_system_tight_noiseless(u):\n",
    "    g1 = 1. - u[0] + u[1] ** 2 + 2. * u[1]  # + np.random.normal(0., np.sqrt(1e-3))\n",
    "    return -g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Benoit Model (Modified Version) for Real Time Optimization without constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant Model \n",
    "def Benoit_Model(u,theta):\n",
    "    f = theta[0] * u[0] ** 2 + theta[1] * u[1] ** 2\n",
    "    return f\n",
    "\n",
    "\n",
    "def con1_model(u,theta):\n",
    "    g1 = 1. - theta[2]*u[0] + theta[3]*u[1] ** 2\n",
    "    return -g1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Optimization on cost function\n",
    "\n",
    "Optimization algorithm on cost function to find optimized input u given parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization on cost function\n",
    "def cost_optimize(theta,u0):\n",
    "    con = ({'type': 'ineq', \n",
    "            'fun': lambda u: con1_model(u,theta)}) \n",
    "    result = minimize(Benoit_Model,\n",
    "                    u0,\n",
    "                    constraints= con,\n",
    "                    method='SLSQP',\n",
    "                    options={'ftol': 1e-9},\n",
    "                    args= (theta))\n",
    "\n",
    "    return result.x,result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 2.00000000e+00 -1.89234472e-08], optimal output: 1.9999999999530884\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "u0 = [1,1] # Initial guess for optimization algorithm\n",
    "theta = [0.5,0.5,0.5,0.5]\n",
    "u,fun = cost_optimize(theta,u0)\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Model Adaptation\n",
    "\n",
    "We try to minimize difference between output of an actual plant and output of a model. \n",
    "\n",
    "The difference is measured by SSE (Sum of Squared Error), which is used for cost function to be minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function of adaptation\n",
    "def SSE(theta,u,plant_func,plant_constraint):\n",
    "\n",
    "    func_diff = plant_func(u) - Benoit_Model(u,theta)\n",
    "    con_diff = plant_constraint(u) - con1_model(u,theta)\n",
    "\n",
    "    return func_diff**2+con_diff**2\n",
    "\n",
    "# Model Adaptation (Optimization of Parameters)\n",
    "def SSE_optimize(plant_func,plant_constraint,theta0,u):\n",
    "\n",
    "    result = minimize(SSE,\n",
    "                      theta0,\n",
    "                      method='SLSQP',\n",
    "                      args= (u,plant_func,plant_constraint),\n",
    "                      options= {'ftol': 1e-9})\n",
    "    \n",
    "    return result.x,result.fun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function:13.0\n",
      "------------\n",
      "optimal hyperparameters:[0.99999998 0.5        2.00000001 0.5       ],\n",
      "optimal function: 1.1170386694296845e-15\n"
     ]
    }
   ],
   "source": [
    "# test for adaptation cost function\n",
    "x = SSE(theta = [0.5,0.5,0.5,0.5],\n",
    "        u = [2,0],\n",
    "        plant_func = Benoit_System_noiseless_1,\n",
    "        plant_constraint =con1_system_noiseless)\n",
    "\n",
    "print(f\"cost function:{x}\")\n",
    "print(\"------------\")\n",
    "\n",
    "# test for model adaptation method\n",
    "theta,fun = SSE_optimize(plant_func=Benoit_System_noiseless_1,\n",
    "                     plant_constraint=con1_system_noiseless,\n",
    "                     theta0=[0.5,0.5,0.5,0.5],\n",
    "                     u=[2.00000000e+00,-1.89234472e-08])\n",
    "\n",
    "print(f\"optimal hyperparameters:{theta},\\noptimal function: {fun}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Overall Algorithm\n",
    "\n",
    "### I. Model Adaptation on \"Benoit_System_noiseless_1\" plant system with \"con1_system_noiseless\" constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 2.00000000e+00 -1.89234472e-08], optimal output: 1.9999999999530884\n",
      "optimal hyperparameters:[0.99999998 0.5        2.00000001 0.5       ], cost: 1.1201679861431565e-15\n",
      "optimal input: [ 4.99999997e-01 -2.01114322e-09], optimal output: 0.2499999930048407\n",
      "optimal hyperparameters:[0.99999998 0.5        5.00000001 0.5       ], cost: 1.021228093130283e-16\n",
      "optimal input: [ 2.00000000e-01 -7.58719882e-09], optimal output: 0.039999999147657936\n",
      "optimal hyperparameters:[ 0.99999998  0.5        10.99999956  0.5       ], cost: 1.1769003276782473e-14\n",
      "optimal input: [ 9.09090946e-02 -7.58719882e-09], optimal output: 0.008264463333250038\n",
      "optimal hyperparameters:[ 0.99999998  0.5        23.00000238  0.5       ], cost: 7.926616316173199e-14\n",
      "optimal input: [ 4.34782564e-02 -7.35436818e-09], optimal output: 0.0018903587452594004\n",
      "optimal hyperparameters:[ 0.99999998  0.5        47.00000596  0.5       ], cost: 1.4051593931378817e-15\n"
     ]
    }
   ],
   "source": [
    "# Initial Guess (k=0)\n",
    "uk = [1,1]\n",
    "thetak = [0.5,0.5,0.5,0.5]\n",
    "\n",
    "# dictionary: uk_1, fun, thetak_1, cost, \n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "\n",
    "    # Model Optimization\n",
    "    uk_1,fun = cost_optimize(theta=thetak,u0=uk)\n",
    "    print(f\"optimal input: {uk_1}, optimal output: {fun}\")\n",
    "    \n",
    "    # Model Adaptation\n",
    "    thetak_1,cost = SSE_optimize(plant_func=Benoit_System_noiseless_1,\n",
    "                        plant_constraint=con1_system_noiseless,\n",
    "                        theta0=thetak,\n",
    "                        u=uk_1)\n",
    "    print(f\"optimal hyperparameters:{thetak_1}, cost: {cost}\")\n",
    "\n",
    "    uk = uk_1\n",
    "    thetak = thetak_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Optimized Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [0. 0.], optimal output: 0.0\n"
     ]
    }
   ],
   "source": [
    "u0 = [1,1] \n",
    "con = ({'type': 'ineq', \n",
    "        'fun': lambda u: con1_system_noiseless(u)}) \n",
    "result = minimize(Benoit_System_noiseless_1,\n",
    "                u0,\n",
    "                constraints= con,\n",
    "                method='SLSQP',\n",
    "                options={'ftol': 1e-9})\n",
    "\n",
    "u = result.x\n",
    "fun = result.fun\n",
    "\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "Notice that actual optimal input is [0,0] while the optimal input from model adaption converges to the model. However, the convergence is done with wrong hyperparameters especially on constraint con1_system_noiseless; notice constant increase in theta[2] (=47 at the last iteration). \n",
    "\n",
    "Moreover, the hyperparameters theta[1], theta[3] (=0.5,0.5) does not change because intermidiate optimal inputs have u[1] = 0 always. If the initial values were [0.1,0.1,0.1,0.1] then theta[1], theta[3] = 0.1 always. This makes hyperparameter to not get changed in model adaptation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Model Adaptation on \"Benoit_System_noiseless_1\" plant system with \"con1_system_tight_noiseless\" constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 2.00000000e+00 -1.89234472e-08], optimal output: 1.9999999999530884\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 2.6598920050906437e-16\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n",
      "optimal input: [ 9.99999986e-01 -7.04835149e-08], optimal output: 0.9999999604125535\n",
      "optimal hyperparameters:[0.99999999 0.5        1.00000001 0.5       ], cost: 1.959903026977365e-14\n"
     ]
    }
   ],
   "source": [
    "# Initial Guess (k=0)\n",
    "uk = [1,1]\n",
    "thetak = [0.5,0.5,0.5,0.5]\n",
    "\n",
    "# dictionary: uk_1, fun, thetak_1, cost, \n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Model Optimization\n",
    "    uk_1,fun = cost_optimize(theta=thetak,u0=uk)\n",
    "    print(f\"optimal input: {uk_1}, optimal output: {fun}\")\n",
    "    \n",
    "    # Model Adaptation\n",
    "    thetak_1,cost = SSE_optimize(plant_func=Benoit_System_noiseless_1,\n",
    "                        plant_constraint=con1_system_tight_noiseless,\n",
    "                        theta0=thetak,\n",
    "                        u=uk_1)\n",
    "    print(f\"optimal hyperparameters:{thetak_1}, cost: {cost}\")\n",
    "\n",
    "    uk = uk_1\n",
    "    thetak = thetak_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Optimized Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 0.3684571  -0.39299332], optimal output: 0.14540320807022292\n"
     ]
    }
   ],
   "source": [
    "u0 = [1,1] \n",
    "con = ({'type': 'ineq', \n",
    "        'fun': lambda u: con1_system_tight_noiseless(u)}) \n",
    "result = minimize(Benoit_System_noiseless_1,\n",
    "                u0,\n",
    "                constraints= con,\n",
    "                method='SLSQP',\n",
    "                options={'ftol': 1e-9})\n",
    "\n",
    "u = result.x\n",
    "fun = result.fun\n",
    "\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "TO BE WRITTEN:\n",
    "\n",
    "The result seems to show the lack of model flexibility, which prevents the optimal input from model to conver to actual optimal input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modifier Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Benoit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant Model \n",
    "def Benoit_Model(u,theta,modifier):\n",
    "\n",
    "    f = theta[0] * u[0] ** 2 + theta[1] * u[1] ** 2 + np.sum(modifier[2] * u)\n",
    "    return f\n",
    "\n",
    "def con1_model(u,u0,theta,modifier):\n",
    "\n",
    "    g1 = 1. - theta[2]*u[0] + theta[3]*u[1] ** 2 + modifier[0] + np.sum(modifier[1]*(u-u0))\n",
    "    return -g1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Optimization on Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_optimize(u0,theta,modifier):\n",
    "\n",
    "    con = ({'type': 'ineq',\n",
    "            'fun': lambda u: con1_model(u,u0,theta,modifier)})\n",
    "    \n",
    "    result = minimize((Benoit_Model),\n",
    "                    u0,\n",
    "                    constraints= con,\n",
    "                    method='SLSQP',\n",
    "                    options= {'ftol': 1e-9},\n",
    "                    args= (theta,modifier))\n",
    "    \n",
    "    return result.x,result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 3.39098837 -0.65105543], optimal output: 6.50869155160146\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "u0 = np.array([10,0]) # Initial guess for optimization algorithm\n",
    "modifier = np.array([-0.6834536267626328,[-0.25      ,  0.74531547],[0.19976909, 0.19976909]],dtype=object) \n",
    "theta = np.array([0.5,0.5,0.5,0.5])\n",
    "\n",
    "u,fun = cost_optimize(u0,theta,modifier)\n",
    "\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Modifier Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient modifier\n",
    "def gradient_estimation(u,fun):\n",
    "    # step\n",
    "    du = np.sqrt(1e-3) # np.finfo\n",
    "\n",
    "    # Predicted gradient from real plant\n",
    "    gradient_u0 = (fun(u+[du,0]) - fun(u))/du\n",
    "    gradient_u1 = (fun(u+[0,du]) - fun(u))/du\n",
    "    gradient = [gradient_u0,gradient_u1]\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "# Modifier Update\n",
    "def modifier_update(u,u0,theta,modifier,plant_fun,plant_con1):\n",
    "    \n",
    "    # Calculate relavent bias and gradients:\n",
    "    gradient_cost_p = gradient_estimation(u,plant_fun)\n",
    "    ## Gradient of plant constraint function\n",
    "    gradient_con1_p = gradient_estimation(u,plant_con1)\n",
    "    ## Gradient of model cost function\n",
    "    gradient_cost_m = approx_fprime(u,Benoit_Model,np.sqrt(1e-3),theta,modifier)\n",
    "    ## Gradient of model constraint function\n",
    "    gradient_con1_m = approx_fprime(u,con1_model,np.sqrt(1e-3),u0,theta,modifier)\n",
    "    ## Gradient of plant cost function\n",
    "\n",
    "    # Calculate difference between plant and model\n",
    "    epsil = -(plant_con1(u) - con1_model(u,u0,theta,modifier))\n",
    "    lamda_0 = -1*(gradient_con1_p - gradient_con1_m)\n",
    "    lamda_1 = gradient_cost_p - gradient_cost_m \n",
    "\n",
    "    return [epsil,lamda_0,lamda_1]\n",
    "\n",
    "# Modifier Adaptation\n",
    "def adaptation(u,u0,theta,modifier,plant_fun,plant_con1,K):\n",
    "    new_modifier = modifier_update(u,u0,theta,modifier,plant_fun,plant_con1)\n",
    "    I = np.identity(np.shape(modifier)[0])\n",
    "\n",
    "    for i in range(np.shape(modifier)[0]):\n",
    "        modifier[i] = (I - K)[i,i]*modifier[i] + K[i,i]*new_modifier[i]\n",
    "\n",
    "    return modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Modifier:\n",
      "[0.4922559867664922 array([0.2      , 0.7244272])\n",
      " array([-0.07620526, -0.07620526])]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "## Variable\n",
    "u = np.array([-0.20316229, -0.80316225])\n",
    "u0 = np.array([-1,-1]) \n",
    "modifier = [1.4000000000000001,[0.5,0.80316228],[0.20316228,0.20316228]]\n",
    "modifier = np.array([np.array(x) for x in modifier],dtype=object)\n",
    "theta = np.array([0.5,0.5,0.5,0.5])\n",
    "plant_fun = Benoit_System_noiseless_1\n",
    "plant_con1 = con1_system_tight_noiseless\n",
    "c\n",
    "\n",
    "# Modifier Adaptation\n",
    "modifier = adaptation(u,u0,theta,modifier,plant_fun,plant_con1,K)\n",
    "print(\"New Modifier:\")\n",
    "print(modifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Overall Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Modifier Adaptation on \"Benoit_System_noiseless_1\" plant system with \"con1_system_tight_noiseless\" constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [ 0.90818371 -0.52507148], optimal output: 0.6268228267804395 \n",
      " modifier: [-0.6835999658963197 array([-0.2499543 ,  0.74524562])\n",
      " array([0.19970882, 0.19970882])]\n"
     ]
    }
   ],
   "source": [
    "uk = np.array([1,1]) \n",
    "modifier = [1,[1,1],[1,1]]\n",
    "modifierk = np.array([np.array(x) for x in modifier],dtype=object)\n",
    "theta = np.array([0.5,0.5,0.5,0.5])\n",
    "plant_fun = Benoit_System_noiseless_1\n",
    "plant_con1 = con1_system_tight_noiseless\n",
    "K = np.identity(np.shape(modifierk)[0])*0.2\n",
    "\n",
    "for i in range(20):\n",
    "    uk_1,fun = cost_optimize(uk,theta,modifierk)\n",
    "    modifierk_1 = adaptation(uk_1,uk,theta,modifierk,plant_fun,plant_con1,K)\n",
    "\n",
    "    uk = uk_1\n",
    "    modifierk = modifierk_1\n",
    "\n",
    "print(f\"optimal input: {uk_1}, optimal output: {fun} \\n modifier: {modifierk_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Optimized Input and Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal input: [-4.97322951e-09 -4.97201070e-09], optimal output: 7.418085245734631e-17\n"
     ]
    }
   ],
   "source": [
    "u0 = [2,1] \n",
    "con = ({'type': 'ineq', \n",
    "        'fun': lambda u: con1_system_noiseless(u)}) \n",
    "result = minimize(Benoit_System_noiseless_1,\n",
    "                u0,\n",
    "                constraints= con,\n",
    "                method='SLSQP',\n",
    "                options={'ftol': 1e-9})\n",
    "\n",
    "u = result.x\n",
    "fun = result.fun\n",
    "\n",
    "print(f\"optimal input: {u}, optimal output: {fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "The algorithm were not able to reach to the global optimization. However, it was able to approach to approximately good local minimum. Morevoer, the local mimimum changes according to theta. \n",
    "\n",
    "This allowed me to reevaluate on what modifier adaptation is doing.\n",
    "- Approximated KKT matching -> prevents the algorithm to find global minimum\n",
    "- Similar to upper confidence bound but without confidence intervals. Cannot perform exploration / only exploitation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
